{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_chapter_6_char-lever_generation_with_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hx8owrIp7m67"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LenaVolzhina/playing-with-neural-networks/blob/master/DL_chapter_6_char_lever_generation_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWqvqTtl0WdO",
        "colab_type": "text"
      },
      "source": [
        "# Загружаю Довлатова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNbSqIdA0WPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://e-libra.ru/read/168185-solo-na-undervude.html\n",
        "text = \"\"\"...\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SWcmlU_EZD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsXZmq-rCLGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_fname_orig = 'dovlatov_ibm_orig.txt'\n",
        "\n",
        "# with open(input_fname_orig, 'w') as fout:\n",
        "#   fout.write(text)\n",
        "\n",
        "with open(input_fname_orig) as fin:\n",
        "  text = fin.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FalutT46CxIz",
        "colab_type": "text"
      },
      "source": [
        "Чищу от лишних символов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzVMnAz5CISs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basic = set(['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?',])\n",
        "cyrillics = set(chr(i) for i in range(ord('А'), ord('я') + 1)) | {'ё'}\n",
        "alphabet = basic | cyrillics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpoobotN0hwV",
        "colab_type": "code",
        "outputId": "7e59b56a-989f-44c6-ab6f-d7b81b995057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_chars = set(text)\n",
        "print(\"Deleting\", sorted(text_chars - alphabet))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleting ['0', '1', '2', '3', '4', '5', '6', '8', '9', '>', '`', 'a', 'b', 'c', 'g', 'i', 'm', 'n', 'o', 'p', 'r', 't', '«', '»', '–', '“', '„', '…', '₽']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJtXS7Q1DLM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_clean = text\n",
        "for char in text_chars - alphabet:\n",
        "  text_clean = text_clean.replace(char, '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcEgj8vsDjBU",
        "colab_type": "code",
        "outputId": "9d02ca5b-b5e4-45e8-e1e6-0cfb4e85c7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(text), len(text_clean)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60727, 59750)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhYyVeAnDQqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_fname = 'dovlatov_ibm.txt'\n",
        "\n",
        "with open(input_fname, 'w') as fout:\n",
        "  fout.write(text_clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvWDPC1B2lsa",
        "colab_type": "text"
      },
      "source": [
        "# Читаю и преобразовываю текст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wvKhCfq3pnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvtgkNNe0D8T",
        "colab_type": "code",
        "outputId": "8ea7daca-246e-4c5c-8818-1ab50bf5eff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "START_CHAR = '\\b'\n",
        "END_CHAR = '\\t'\n",
        "PADDING_CHAR = '\\a'\n",
        "\n",
        "chars = set( [START_CHAR, '\\n', END_CHAR] )\n",
        "with open(input_fname) as f:\n",
        "  for line in f:\n",
        "    chars.update( list(line.strip().lower()) )\n",
        "\n",
        "char_indices = { c : i for i, c in enumerate(sorted(list(chars))) }\n",
        "print(repr(sorted(list(chars))[0]))\n",
        "char_indices[PADDING_CHAR] = 0    # а то, что раньше было 0, куда?\n",
        "indices_to_chars = { i : c for c,i in char_indices.items() }\n",
        "num_chars = len(chars)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\x08'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEfT4rJ03AWm",
        "colab_type": "code",
        "outputId": "37b42dc4-2d29-4fbd-c03d-fea804c044dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "indices_to_chars"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\x07',\n",
              " 1: '\\t',\n",
              " 2: '\\n',\n",
              " 3: ' ',\n",
              " 4: '!',\n",
              " 5: '\"',\n",
              " 6: '(',\n",
              " 7: ')',\n",
              " 8: ',',\n",
              " 9: '-',\n",
              " 10: '.',\n",
              " 11: ':',\n",
              " 12: '?',\n",
              " 13: 'а',\n",
              " 14: 'б',\n",
              " 15: 'в',\n",
              " 16: 'г',\n",
              " 17: 'д',\n",
              " 18: 'е',\n",
              " 19: 'ж',\n",
              " 20: 'з',\n",
              " 21: 'и',\n",
              " 22: 'й',\n",
              " 23: 'к',\n",
              " 24: 'л',\n",
              " 25: 'м',\n",
              " 26: 'н',\n",
              " 27: 'о',\n",
              " 28: 'п',\n",
              " 29: 'р',\n",
              " 30: 'с',\n",
              " 31: 'т',\n",
              " 32: 'у',\n",
              " 33: 'ф',\n",
              " 34: 'х',\n",
              " 35: 'ц',\n",
              " 36: 'ч',\n",
              " 37: 'ш',\n",
              " 38: 'щ',\n",
              " 39: 'ъ',\n",
              " 40: 'ы',\n",
              " 41: 'ь',\n",
              " 42: 'э',\n",
              " 43: 'ю',\n",
              " 44: 'я'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m85LITa42tJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_one(i, sz):\n",
        "  res = np.zeros(sz)\n",
        "  res[i] = 1\n",
        "  return res\n",
        "\n",
        "char_vectors = {\n",
        "  c : (np.zeros(num_chars) if c == PADDING_CHAR else get_one(v, num_chars))\n",
        "  for c,v in char_indices.items()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE3QzXmW2xpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read sentences\n",
        "\n",
        "sentence_end_markers = set( '.!?' )\n",
        "\n",
        "sentences = []\n",
        "current_sentence = ''\n",
        "with open( input_fname, 'r' ) as f:\n",
        "  for line in f:\n",
        "    s = line.strip().lower()\n",
        "    if len(s) > 0:\n",
        "      current_sentence += s + '\\n'\n",
        "    if len(s) == 0 or s[-1] in sentence_end_markers:\n",
        "      current_sentence = current_sentence.strip()\n",
        "      if len(current_sentence) > 10:\n",
        "        sentences.append(current_sentence)\n",
        "      current_sentence = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVvZXIlK34Sk",
        "colab_type": "code",
        "outputId": "f33c108c-9765-4b11-b45c-26914f952554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences[102]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'трудная книга. но хорошая. говорят.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1DBCDkqBRM6",
        "colab_type": "code",
        "outputId": "7f8a5545-da96-421a-e63d-4a80dc24e1f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "sentence_lengths = np.array([len(s) for s in sentences])\n",
        "plt.hist(sentence_lengths)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([256., 139.,  91.,  29.,  18.,   8.,   2.,   3.,   0.,   2.]),\n",
              " array([ 11. ,  73.9, 136.8, 199.7, 262.6, 325.5, 388.4, 451.3, 514.2,\n",
              "        577.1, 640. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkOEuSR36f3DeKVqq5mBJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "506x-eI9362I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize\n",
        "\n",
        "def get_matrices(sentences):\n",
        "  max_sentence_len = np.max([ len(x) for x in sentences ])\n",
        "  X = np.zeros((len(sentences), max_sentence_len, len(chars)), dtype=np.bool)\n",
        "  y = np.zeros((len(sentences), max_sentence_len, len(chars)), dtype=np.bool)\n",
        "  for i, sentence in enumerate(sentences):\n",
        "    char_seq = (START_CHAR + sentence + END_CHAR).ljust(\n",
        "      max_sentence_len+1, PADDING_CHAR    # заполняем до \"конца\"\n",
        "    )\n",
        "    for t in range(max_sentence_len):\n",
        "      X[i, t, :] = char_vectors[char_seq[t]]\n",
        "      y[i, t, :] = char_vectors[char_seq[t+1]]\n",
        "  return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egL3-lsG4WOC",
        "colab_type": "text"
      },
      "source": [
        "# Строим простую модель: один уровень LSTM-ячеек"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR4bd_OF8YzK",
        "colab_type": "text"
      },
      "source": [
        "## Описываем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuD0g6F14Uc1",
        "colab_type": "code",
        "outputId": "6c4f2402-6d97-40d2-99df-ca1c28686eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, TimeDistributed, Activation\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "  output_dim=128,   # слой состоит из 128 ячеек, оно же размерность выхода\n",
        "  activation='tanh',  # по умолчанию сигмоида\n",
        "  return_sequences=True, # выдавать выходы после каждого примера, \n",
        "                         # а не после всей посоедовательности\n",
        "  input_dim=num_chars   # размерность входного вектора для одного символа\n",
        "))\n",
        "\n",
        "# дропаут в RNN -- дело тонкое\n",
        "# обычно только между слоями, не внутри ячейки. но сейчас мнение сдвигается\n",
        "# пока ограничимся обычным, между слоями, обсудим позже\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# одни и те же веса по всей длине входной последовательности (shared weights)\n",
        "model.add(TimeDistributed(Dense(output_dim=num_chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, input_shape=(None, 45), units=128)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=45)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjDL9OXA7ShO",
        "colab_type": "text"
      },
      "source": [
        "## Оптимизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82HL9PnN7Hdx",
        "colab_type": "text"
      },
      "source": [
        "Чтобы градиенты в рекуррентной сети не взрывались, их обязательно нужно купировать, обрезать до некоторого максимально допустимого размера (по-английски это называется gradient clipping)\n",
        "\n",
        "* clipnorm будет масштабировать вектор градиента так, чтобы его норма не превысила заданного порога;\n",
        "* clipvalue будет просто обрезать до заданного порога каждую компоненту градиента по отдельности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn8cWdnU7O_D",
        "colab_type": "code",
        "outputId": "3bcf7e64-2c66-4a6a-8153-e94da3bdf997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=Adam(clipnorm=1.), \n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx8owrIp7m67",
        "colab_type": "text"
      },
      "source": [
        "## Генерация батчей\n",
        "\n",
        "В порядке возрастания длины предложения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdHVCZrk7Y_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_indices = np.random.choice(range(len(sentences)), int(len(sentences) * 0.05))\n",
        "sentences_train = [\n",
        "  sentences[x]\n",
        "  for x in set(range(len(sentences))) - set(test_indices) \n",
        "]\n",
        "sentences_test = [sentences[x] for x in test_indices]\n",
        "sentences_train = list(sorted(sentences_train, key = lambda x : len(x)))\n",
        "X_test, y_test = get_matrices(sentences_test)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "def generate_batch():\n",
        "  while True:\n",
        "    for i in range( int(len(sentences_train) / batch_size) ):\n",
        "      sentences_batch = sentences_train[ i*batch_size : (i+1)*batch_size ]\n",
        "      yield get_matrices(sentences_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPAKbz4V8KAv",
        "colab_type": "text"
      },
      "source": [
        "## Сэмплер примеров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwjWMAKn8fmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "\n",
        "class CharSampler(Callback):\n",
        "  def __init__(self, char_vectors, model, output_fname, step):\n",
        "    self.char_vectors = char_vectors\n",
        "    self.model = model\n",
        "    self.output_fname = output_fname\n",
        "    self.step = step\n",
        "\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.epoch = 0\n",
        "    if os.path.isfile(self.output_fname):\n",
        "      os.remove(self.output_fname)\n",
        "\n",
        "  def sample(self, preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "  def sample_one(self, T):\n",
        "    # get one sentence\n",
        "    result = START_CHAR\n",
        "    while len(result) < 500:\n",
        "      Xsampled = np.zeros( (1, len(result), num_chars) )\n",
        "      for t, c in enumerate( list( result ) ):\n",
        "        Xsampled[0,t,:] = self.char_vectors[ c ]\n",
        "      ysampled = self.model.predict( Xsampled, batch_size=1 )[0,:]\n",
        "      yv = ysampled[len(result)-1,:]\n",
        "      selected_char = indices_to_chars[ self.sample( yv, T ) ]\n",
        "      if selected_char == END_CHAR:\n",
        "        break\n",
        "      result = result + selected_char\n",
        "    return result\n",
        "\n",
        "  def on_epoch_end(self, batch, logs={}):\n",
        "    self.epoch = self.epoch + 1\n",
        "    if self.epoch % self.step == 0:\n",
        "      print(\"\\nEpoch %d text sampling:\" % self.epoch)\n",
        "      with open( self.output_fname, 'a' ) as outf:\n",
        "        outf.write( '\\n===== Epoch %d =====\\n' % self.epoch )\n",
        "        for T in [0.3, 0.5, 0.7, 0.9, 1.1]:\n",
        "          print('\\tsampling, T = %.1f...' % T)\n",
        "          for _ in range(5):\n",
        "            self.model.reset_states()\n",
        "            res = self.sample_one(T)\n",
        "            outf.write( '\\nT = %.1f\\n%s\\n' % (T, res[1:]) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JQyPjuP7643",
        "colab_type": "text"
      },
      "source": [
        "### Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-qNGEJ713H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "\n",
        "filename = \"simple_model_{}.log\"\n",
        "\n",
        "cb_sampler = CharSampler(char_vectors, model, filename.format('sampler'), step=5)\n",
        "cb_logger = CSVLogger(filename.format('csv'))\n",
        "cb_checkpoint = ModelCheckpoint(filename.format('val_loss'), monitor='val_loss') #, verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0NUSfk8-KWP",
        "colab_type": "text"
      },
      "source": [
        "## Обучаем!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W5ToJLV99Tu",
        "colab_type": "code",
        "outputId": "a6b9fcf8-7b74-4ce6-8df4-5337a97d18c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit_generator(\n",
        "  generate_batch(),\n",
        "  int(len(sentences_train) / batch_size) * batch_size,   # объем X\n",
        "  nb_epoch=50, verbose=True, \n",
        "  validation_data = (X_test, y_test),\n",
        "  callbacks=[cb_logger, cb_sampler]#, cb_checkpoint] \n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "  3/512 [..............................] - ETA: 19s - loss: 2.6294 - acc: 0.1977"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 512, verbose=True, validation_data=(array([[[..., callbacks=[<keras.ca..., epochs=50)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "512/512 [==============================] - 58s 114ms/step - loss: 2.4522 - acc: 0.2509 - val_loss: 0.4692 - val_acc: 0.0539\n",
            "Epoch 2/50\n",
            "512/512 [==============================] - 58s 114ms/step - loss: 2.2532 - acc: 0.3037 - val_loss: 0.4536 - val_acc: 0.0586\n",
            "Epoch 3/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 2.0951 - acc: 0.3512 - val_loss: 0.4487 - val_acc: 0.0615\n",
            "Epoch 4/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 1.9508 - acc: 0.3944 - val_loss: 0.4579 - val_acc: 0.0600\n",
            "Epoch 5/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 1.8069 - acc: 0.4374 - val_loss: 0.4738 - val_acc: 0.0576\n",
            "\n",
            "Epoch 5 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 6/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.6898 - acc: 0.4708 - val_loss: 0.4739 - val_acc: 0.0592\n",
            "Epoch 7/50\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 1.5889 - acc: 0.5007 - val_loss: 0.4962 - val_acc: 0.0565\n",
            "Epoch 8/50\n",
            "512/512 [==============================] - 62s 121ms/step - loss: 1.5071 - acc: 0.5243 - val_loss: 0.5033 - val_acc: 0.0572\n",
            "Epoch 9/50\n",
            "512/512 [==============================] - 62s 120ms/step - loss: 1.4326 - acc: 0.5458 - val_loss: 0.5090 - val_acc: 0.0562\n",
            "Epoch 10/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.3926 - acc: 0.5576 - val_loss: 0.5173 - val_acc: 0.0572\n",
            "\n",
            "Epoch 10 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 11/50\n",
            "512/512 [==============================] - 61s 120ms/step - loss: 1.3535 - acc: 0.5680 - val_loss: 0.5266 - val_acc: 0.0571\n",
            "Epoch 12/50\n",
            "512/512 [==============================] - 61s 118ms/step - loss: 1.3113 - acc: 0.5791 - val_loss: 0.5286 - val_acc: 0.0557\n",
            "Epoch 13/50\n",
            "512/512 [==============================] - 61s 118ms/step - loss: 1.2760 - acc: 0.5896 - val_loss: 0.5382 - val_acc: 0.0566\n",
            "Epoch 14/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.2537 - acc: 0.5962 - val_loss: 0.5441 - val_acc: 0.0555\n",
            "Epoch 15/50\n",
            "512/512 [==============================] - 61s 118ms/step - loss: 1.2213 - acc: 0.6049 - val_loss: 0.5523 - val_acc: 0.0555\n",
            "\n",
            "Epoch 15 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 16/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.1980 - acc: 0.6127 - val_loss: 0.5614 - val_acc: 0.0554\n",
            "Epoch 17/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.1835 - acc: 0.6167 - val_loss: 0.5729 - val_acc: 0.0555\n",
            "Epoch 18/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 1.1674 - acc: 0.6203 - val_loss: 0.5812 - val_acc: 0.0535\n",
            "Epoch 19/50\n",
            "512/512 [==============================] - 59s 116ms/step - loss: 1.1557 - acc: 0.6229 - val_loss: 0.5664 - val_acc: 0.0554\n",
            "Epoch 20/50\n",
            "512/512 [==============================] - 60s 116ms/step - loss: 1.1376 - acc: 0.6288 - val_loss: 0.5740 - val_acc: 0.0541\n",
            "\n",
            "Epoch 20 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 21/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 1.1201 - acc: 0.6339 - val_loss: 0.5795 - val_acc: 0.0542\n",
            "Epoch 22/50\n",
            "512/512 [==============================] - 59s 116ms/step - loss: 1.1075 - acc: 0.6368 - val_loss: 0.5924 - val_acc: 0.0553\n",
            "Epoch 23/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.0997 - acc: 0.6382 - val_loss: 0.5869 - val_acc: 0.0561\n",
            "Epoch 24/50\n",
            "512/512 [==============================] - 59s 116ms/step - loss: 1.0927 - acc: 0.6410 - val_loss: 0.5895 - val_acc: 0.0542\n",
            "Epoch 25/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.0778 - acc: 0.6455 - val_loss: 0.6009 - val_acc: 0.0542\n",
            "\n",
            "Epoch 25 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 26/50\n",
            "512/512 [==============================] - 60s 116ms/step - loss: 1.0678 - acc: 0.6479 - val_loss: 0.6073 - val_acc: 0.0550\n",
            "Epoch 27/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.0532 - acc: 0.6521 - val_loss: 0.6003 - val_acc: 0.0548\n",
            "Epoch 28/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.0475 - acc: 0.6530 - val_loss: 0.6069 - val_acc: 0.0564\n",
            "Epoch 29/50\n",
            "512/512 [==============================] - 60s 116ms/step - loss: 1.0388 - acc: 0.6560 - val_loss: 0.6114 - val_acc: 0.0545\n",
            "Epoch 30/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.0313 - acc: 0.6582 - val_loss: 0.6079 - val_acc: 0.0564\n",
            "\n",
            "Epoch 30 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 31/50\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 1.0232 - acc: 0.6603 - val_loss: 0.6167 - val_acc: 0.0559\n",
            "Epoch 32/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.0167 - acc: 0.6619 - val_loss: 0.6067 - val_acc: 0.0557\n",
            "Epoch 33/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 1.0114 - acc: 0.6637 - val_loss: 0.6155 - val_acc: 0.0557\n",
            "Epoch 34/50\n",
            "512/512 [==============================] - 60s 116ms/step - loss: 1.0062 - acc: 0.6654 - val_loss: 0.6196 - val_acc: 0.0575\n",
            "Epoch 35/50\n",
            "512/512 [==============================] - 59s 114ms/step - loss: 1.0011 - acc: 0.6659 - val_loss: 0.6266 - val_acc: 0.0570\n",
            "\n",
            "Epoch 35 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 36/50\n",
            "512/512 [==============================] - 59s 116ms/step - loss: 0.9942 - acc: 0.6673 - val_loss: 0.6236 - val_acc: 0.0563\n",
            "Epoch 37/50\n",
            "512/512 [==============================] - 60s 117ms/step - loss: 0.9868 - acc: 0.6703 - val_loss: 0.6318 - val_acc: 0.0546\n",
            "Epoch 38/50\n",
            "512/512 [==============================] - 59s 116ms/step - loss: 0.9812 - acc: 0.6714 - val_loss: 0.6281 - val_acc: 0.0569\n",
            "Epoch 39/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 0.9743 - acc: 0.6738 - val_loss: 0.6291 - val_acc: 0.0557\n",
            "Epoch 40/50\n",
            "512/512 [==============================] - 60s 118ms/step - loss: 0.9703 - acc: 0.6747 - val_loss: 0.6259 - val_acc: 0.0578\n",
            "\n",
            "Epoch 40 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 41/50\n",
            "512/512 [==============================] - 61s 118ms/step - loss: 0.9676 - acc: 0.6758 - val_loss: 0.6352 - val_acc: 0.0555\n",
            "Epoch 42/50\n",
            "512/512 [==============================] - 67s 130ms/step - loss: 0.9628 - acc: 0.6773 - val_loss: 0.6434 - val_acc: 0.0548\n",
            "Epoch 43/50\n",
            "512/512 [==============================] - 67s 131ms/step - loss: 0.9577 - acc: 0.6779 - val_loss: 0.6430 - val_acc: 0.0555\n",
            "Epoch 44/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 0.9503 - acc: 0.6804 - val_loss: 0.6375 - val_acc: 0.0551\n",
            "Epoch 45/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 0.9455 - acc: 0.6811 - val_loss: 0.6327 - val_acc: 0.0553\n",
            "\n",
            "Epoch 45 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 46/50\n",
            "512/512 [==============================] - 60s 116ms/step - loss: 0.9448 - acc: 0.6817 - val_loss: 0.6426 - val_acc: 0.0552\n",
            "Epoch 47/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 0.9416 - acc: 0.6819 - val_loss: 0.6422 - val_acc: 0.0561\n",
            "Epoch 48/50\n",
            "512/512 [==============================] - 59s 114ms/step - loss: 0.9360 - acc: 0.6842 - val_loss: 0.6478 - val_acc: 0.0565\n",
            "Epoch 49/50\n",
            "512/512 [==============================] - 59s 114ms/step - loss: 0.9334 - acc: 0.6850 - val_loss: 0.6486 - val_acc: 0.0550\n",
            "Epoch 50/50\n",
            "512/512 [==============================] - 59s 115ms/step - loss: 0.9283 - acc: 0.6862 - val_loss: 0.6433 - val_acc: 0.0564\n",
            "\n",
            "Epoch 50 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f39619df6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vna-kd_hi35W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77a5b502-f39c-46d8-cd55-91717e38d852"
      },
      "source": [
        "with open('simple_model_sampler.log') as fin:\n",
        "  print(fin.read())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Epoch 5 =====\n",
            "\n",
            "T = 0.3\n",
            "с посторьше была тоть к пристве не догоденсимает провоский молодице. не сыватиль кам ту реду. постора в провом отнити продовом была не постросивать в пестернов меня.\n",
            "\n",
            "T = 0.3\n",
            "сказал:\n",
            "тоненого вы спрашивает:\n",
            "на петеве не зазнотом не зазнимать вы подели в деловек.\n",
            "\n",
            "T = 0.3\n",
            "да мое тобеда та просил севнесь даль е теме не зазалитесь еста. и несказал в простой. в ответ просомойного сельше говорю.\n",
            "\n",
            "T = 0.3\n",
            "пристоло и не была так его вылсял стали м разаные.\n",
            "\n",
            "T = 0.3\n",
            "на чимо реднакова верехо обы зались деле не просторил сказал:\n",
            "мы вышь поэто мниного спросила тетедна. он был дела не притволиль не зазамные такатова.\n",
            "\n",
            "T = 0.5\n",
            "удиль молодим белетповил мольной капрова вселивать каз кат.\n",
            "\n",
            "T = 0.5\n",
            "разве ты дрематург?!\n",
            "\n",
            "T = 0.5\n",
            "тот каканали  пидела дого причемола не прастиласть не подникова северий в простой. примелал с половочество в семен. не однето протеси. тогда вы вого на драгорасть мереже заманить в пестурьнин левно прокому: веряель в ответ прозвестенинов ручелинь молочесное накодного пореденые спрашиваюшья, до закой полебиналесь оговочитель омона всевресываль душего на говорит:\n",
            "правыв непескинаят сарен каз малитеть вогда го заломой обетроновает сразила тоть дале с пошой тесть на сталилсть я не протовал воньюту \n",
            "\n",
            "T = 0.5\n",
            "де какой ра стабительна с вореднождого поредели с брого спрошись в такана?\n",
            "\n",
            "T = 0.5\n",
            "я себишал весь.\n",
            "\n",
            "T = 0.7\n",
            "тская на тейце пожелили договше матома не разваютсявать.\n",
            "\n",
            "T = 0.7\n",
            "у, ждовили когда до прихорошиваетестовайкий кантаков онезнажи и пенева долого деля тал текика стон ождати мы тогданонир. ов пестоланчим споходие! я сараша засемой пелеба ленинать.\n",
            "\n",
            "T = 0.7\n",
            "так я ты чего у семинал:\n",
            "чу ко тосской задую. стодали е отеднаки омачема:\n",
            "дорьской оврес. де мы мыло ростопился ты вордущей кам инерконо. и выдел боздринстерник опровомит:\n",
            "беледен и ток постраявелистере?!\n",
            "\n",
            "T = 0.7\n",
            "какая разница?\n",
            "\n",
            "T = 0.7\n",
            "салубиха тосемой бакавый молода,  но драматергу. каз стабной седна.\n",
            "\n",
            "T = 0.9\n",
            "ответил:\n",
            "и овссмурил:\n",
            "говорий. у внемачто вы ну лизантым.\n",
            "\n",
            "T = 0.9\n",
            "наюдим голово стихать. речах серя сабланоле оменищоденичину?\n",
            "\n",
            "T = 0.9\n",
            "я это делевой больше тогдаль егу плиниль затая не здебеловик капранили чапедву, драмстар?\n",
            "\n",
            "T = 0.9\n",
            "вол-фо оне скарал:\n",
            "лювие этоко наказа мыннум чатаду ст(юлоры а лени.:\n",
            "его с пешь онга ты другаенин у \n",
            "астобелизу, стоть в далодо! всочести да еве прозожиноворисви:\n",
            "мледный пойдени? шигеня пристыва толяко в лет.\n",
            "\n",
            "T = 0.9\n",
            "начал принже гу уснивали ь изупинщае с борве. пошел в дол. приечел, правдомую молотаки реженщисови. пяду с балошие казшле скуша:\n",
            "вы собе голинезневскоидьским мольмей,. встолойет, я собщалась заминате такоменти?\n",
            "\n",
            "T = 1.1\n",
            "не. я как пасалувчаие з божа ю выли ледь молонь имейщий. тольном доймме!\n",
            "\n",
            "T = 1.1\n",
            "у севенике накрачашту говорю. зать, долети еменсоворимноет накого дадка. с ласа. напретоваео гу. жа проанто зчесть. сетита кусрые. выля учтижь ушка?\n",
            "\n",
            "T = 1.1\n",
            "тов толензлги то, чно я седе омнезнно чам!у.\n",
            "\n",
            "T = 1.1\n",
            "-драмотур сказал:\n",
            "туниже ни былся теси. жебев рочеет видова зазан.тыетикбинай невились человетим ревшескего мыложа, паресу:\n",
            "дужято же игося левик:\n",
            "в шего ошнарись правнивы. пражитовие, но зфрумные питзели загхода! одян посоржевай еврейный неваегу?\n",
            "\n",
            "T = 1.1\n",
            "так на онажме ные лни дугапь причетьлленым. содилия про?ба. собышал онмигатуе остаравыетьен: твреду встили снадим анчесторо. послишега это напчаства. когу, срабой доше. в такает. легда тесямый блоско. азника пиршейнигов. какосый фоэтор:\n",
            "трюдиз мне датель редадвие люзаримын все оненослонок духлезана с дю?\n",
            "\n",
            "===== Epoch 10 =====\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "на так как же?\n",
            "\n",
            "T = 0.3\n",
            "а что такое?\n",
            "\n",
            "T = 0.3\n",
            "да так, развесила ь восьте какось в дальее у сказал:\n",
            "мой боктер ской обонат. в ресущис водь с проворитем мороданцию. напривалимом заваратаська говерче.\n",
            "\n",
            "T = 0.5\n",
            "что именно?\n",
            "\n",
            "T = 0.5\n",
            "мало моень ему жения гоза на проудалия. и вот польной долодет.\n",
            "\n",
            "T = 0.5\n",
            "как гаворы,  говори,  отвенил я провниц ответил:\n",
            "в овет в раму. замушли с больше в оттененский.\n",
            "\n",
            "T = 0.5\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.5\n",
            "наачим зарабатывать!\n",
            "\n",
            "T = 0.7\n",
            "токменноя сомная приместо плерен вотернец росита какран верелся в истельной будет. изати ме на одва пишельной. и тыбадрался гомуцый. то жени в тайника. и в ленем не лединелся. пого спилая и сказал:\n",
            "что теке одена пореда пили!\n",
            "\n",
            "T = 0.7\n",
            "да, я еревая будьт мулось поворе а сарама горьно. поредецуй родос веро, произсе кленая..\n",
            "\n",
            "T = 0.7\n",
            "пришел мень рат кренсура.\n",
            "\n",
            "T = 0.7\n",
            "почему? смишал его в стронов. и спришиваю.\n",
            "\n",
            "T = 0.7\n",
            "говорило м голов. какоя разни и появленил мейнер опровенова. он был ереде спольши, какого сполитил алука в старен. и брам, зароски и попол помей.\n",
            "\n",
            "T = 0.9\n",
            "был мол, что!\n",
            "\n",
            "T = 0.9\n",
            "напечатали рассказ?.?\n",
            "\n",
            "T = 0.9\n",
            "эти как это остетсла и водилаза свидив а боре! на в ходу спрадилаю, что тет ромсявны? и аздех водно скратила. дему. се-то не посполслисила.\n",
            "\n",
            "T = 0.9\n",
            "да мое  больше на стако прихоме тимень!\n",
            "\n",
            "T = 0.9\n",
            "приятел как всповсли. в грвор. году полови с грамину. спрашивает:\n",
            "что же то на оса шполизнелся. напочататие в резчук?\n",
            "\n",
            "T = 1.1\n",
            "брался  о мне начай асторетскойо, коша \n",
            "\n",
            "T = 1.1\n",
            "\n",
            "есввет в зноного дыла этобе оссерышле. комыму его удиена. подчалю томон. как это вец. этосикзаромно женезно это скраровна:\n",
            "вых ла не декгальюри, текика. я серда ме омен. румной непила?!\n",
            "\n",
            "T = 1.1\n",
            "напимот, головы и убиметнол\n",
            "\n",
            "T = 1.1\n",
            "залеви покзазял на лишя боть латил водшеесиве. с бутле ры купиша. ! и лыдню, жинка в песли огдваю пушкит стар ка несирабсявать врех хорчесопи ваелиаа бораски.\n",
            "\n",
            "T = 1.1\n",
            "какая разница?\n",
            "\n",
            "===== Epoch 15 =====\n",
            "\n",
            "T = 0.3\n",
            "больше  никогда!\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "больше  никогда!\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "поледин с очностиков. сказал:\n",
            "мол она болье о него простова.\n",
            "\n",
            "T = 0.5\n",
            "не пойдей с орстобновском оторный бересе наеть каньен о бестето. семину спрашивает:\n",
            "я кат проденил  редом. подомал в хорой, хорода. полетовать.\n",
            "\n",
            "T = 0.5\n",
            "ну, мне интересно.\n",
            "\n",
            "T = 0.5\n",
            "толенно  они нака продвал. не женно она настоплесь.\n",
            "\n",
            "T = 0.5\n",
            "и не обиделся.\n",
            "\n",
            "T = 0.5\n",
            "что интересно?\n",
            "\n",
            "T = 0.7\n",
            "ту седнае. морану верьмуениястой не задемитнокосканалко вы броскиха та  пепопвится и волит. податумит, что ерстак. ответ леснико такерскам  запомнок.\n",
            "\n",
            "T = 0.7\n",
            "какой у него телефон?\n",
            "\n",
            "T = 0.7\n",
            "что интересно?\n",
            "\n",
            "T = 0.7\n",
            "и не обиделся.\n",
            "\n",
            "T = 0.7\n",
            "тега я сернался.\n",
            "\n",
            "T = 0.9\n",
            "напечатали.\n",
            "\n",
            "T = 0.9\n",
            "ды слачали овет слазов. быловатилицаяя тенно каклиноваров, на вочной у меня.\n",
            "\n",
            "T = 0.9\n",
            "что именно?\n",
            "\n",
            "T = 0.9\n",
            "пошел обнинавись, вельфу де. было эту каушкин. я ин болст так, устакрые. хожитля какла что-то эти вареел чароден. ониц отхороза бенеревакир?!..\n",
            "\n",
            "T = 0.9\n",
            "и вос болько о говорил:\n",
            "я недувал на овретиче?\n",
            "\n",
            "T = 1.1\n",
            "двожил: просмы ту голоси пилякинактурить, сказ балитор у не удкова тепроксиветки. что от клиберонкрееснеча скожинзу бирет. дот мелжаю водночтоме. я фремзаници прдошу не мину ди. я днучульном дакому пожому. с пичом. в томнец, маристьзят смоллф майножерывей. учисать кром, всод, как жеврей батевзаналь и казатици..\n",
            "\n",
            "T = 1.1\n",
            "приянтое сканальска?\n",
            "\n",
            "T = 1.1\n",
            "что ты мы уси оноциис больфо. а такац а. амурю, я беркой задел запряет.\n",
            "\n",
            "T = 1.1\n",
            "грубвий з запеходанчива:\n",
            "ьго рузвестно?\n",
            "\n",
            "T = 1.1\n",
            "я не друматурги. толоду глого поспродовули:\n",
            "впельеу те с босет боел сараман. из дого проосим билу с паватриим.\n",
            "\n",
            "===== Epoch 20 =====\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "не то тако,  восельсявтенько у бетрода заница одненной был, долостя,  напривеленного. загоновем обрасила спровили:\n",
            "вы вом польне влого не брте. неду не подвука. меня текеро спрасила арчес в ремук.\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?. беду подалином вотренской.\n",
            "\n",
            "T = 0.5\n",
            "де жилонтем на страки?\n",
            "\n",
            "T = 0.5\n",
            "прочем тудинатся гденье от повотельном. послидение  беле дамоетисть в тукланцицаю дерей, полазал перават лашкужды. полечим его отватиль ватьми. теме собралаль,  азветил говор.\n",
            "\n",
            "T = 0.5\n",
            "послабиле ни сталь они деля. ответил:\n",
            "поят даль серга на доет.\n",
            "\n",
            "T = 0.5\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.5\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.7\n",
            "насемин из било подеран. ниго селень кой-то в грусту.\n",
            "\n",
            "T = 0.7\n",
            "но ты прихорашиваешься!\n",
            "\n",
            "T = 0.7\n",
            "мужидал его на моег, что ин изденявы памова и пришетку. куких вальну, дом его спрасилать, что де мую это изались а закомот?\n",
            "\n",
            "T = 0.7\n",
            "все молчат.\n",
            "\n",
            "T = 0.7\n",
            "да, я ерей обудил я глугодноко рочедки обизастовнов какилав.\n",
            "\n",
            "T = 0.9\n",
            "леза ни тук я же но уда?! мирошиг шай. на тал развасають.\n",
            "\n",
            "T = 0.9\n",
            "лего не оде быль а туклинувиро. гали и причнелинь у.\n",
            "\n",
            "T = 0.9\n",
            "напроды,  илашименным  феликцаю. дого оден его не челов дворю. не что поденьга в седрал. и подульше?\n",
            "\n",
            "T = 0.9\n",
            "стачал хила невознич. затомой онбазальной и погластисто. что годстым  пистерой, мыровшенае ветрумые. это покукту, честь расстанти. котдел, не здровстве, пудали с аследойнек. рез, никая скашла.\n",
            "\n",
            "T = 0.9\n",
            "и не обидьенся рем прости\n",
            "\n",
            "T = 1.1\n",
            "прошуо болоде. мой, у всомущевие, мого удяжол вомутьту.\n",
            "\n",
            "T = 1.1\n",
            "однавстрат. мне казалься не потей смолят!\n",
            "\n",
            "T = 1.1\n",
            "полколнинс мыреголской да. поремал униче. сежа роковной могори опросимолная полюра битой.\n",
            "\n",
            "T = 1.1\n",
            "ли на дольной?  отватил ве!\n",
            "\n",
            "T = 1.1\n",
            "какой на четецьи, вожи о ничала тамен юридалькон. мне чем-то за линима я не продой. пушет обронно дено накадумияшь, мезялы. каконы с провоста.  вотренан папелиме тводное претахезаляг а захада?! двамую ций елоу бетодинскай еронском.\n",
            "\n",
            "===== Epoch 25 =====\n",
            "\n",
            "T = 0.3\n",
            "наказал гол скамалочатс валовейскав. дого редие онт выстриковниц из одимили скомой полединствого с брошки.\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.3\n",
            "ну, антисоветский. какая разница. по женина собятнов ответтела прандавился.\n",
            "\n",
            "T = 0.5\n",
            "меня ленног. встом деливаю скатала селя не устенил. полечал в пелье узалиные марановак. стоя быа дражастврур прадустви.\n",
            "\n",
            "T = 0.5\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.5\n",
            "не то прихоритиль скова песташе тебя скану.\n",
            "\n",
            "T = 0.5\n",
            "ну, а тведили гото с валейскай болетенный говся.\n",
            "\n",
            "T = 0.5\n",
            "я не драматург?!\n",
            "\n",
            "T = 0.7\n",
            "напечатали.\n",
            "\n",
            "T = 0.7\n",
            "ну, и все-то хорестилесь говоряк:\n",
            "изушим шилеф-то м будятречем будь о чаломанскай. от брас еде поделенская постаеть еще вотим фирама.\n",
            "\n",
            "T = 0.7\n",
            "проскойчис онодном ответил:\n",
            "вай гавнию мужей. подну мой ответил вешьма  изарфоския респоланитвима не пилелев. мол гол не слашивает:\n",
            "шила человы  пеэтимканирую. драм туп повлично, безаканая на она поницаюсь дараво. пийше с примяян, что он сказал себечаю евсесь о бето чего изание матень. онакцаю мурнал кай как фитов ресторы. послуша тоговой подела замарутюравате сужилию а занем этом фрумов повский ладница. дете то женовал я такова. он посдражила усть. почему женинец и тострыйсковарда.\n",
            "\n",
            "T = 0.7\n",
            "ну, а все-таки, что он сказал?\n",
            "\n",
            "T = 0.7\n",
            "счара с варех обнатовал в того слашил а фомой. не одимо дени больше внего на делей. она коменко устанивы в растракой брскита. их ов бустедь, м тога шинобо почее поэто на лихот. почему не лидней емушго! семитетко посладали евиетав.\n",
            "\n",
            "T = 0.9\n",
            "деньги получил?\n",
            "\n",
            "T = 0.9\n",
            "и несе пойдечелим. всо дунили ови сашкенов. он букае другатургл. в худив его себя изнисель, дого ончарадь не дума. было в пишел драмитский.\n",
            "\n",
            "T = 0.9\n",
            "шелейного бы мернов остинов. зательнем залазиатькон оказат. говсовастул я кон-то скозартна. ответила и ни начакогодник в окопраникавально мужитемно кометов. а тоб а дель ботько  напопелена.\n",
            "\n",
            "T = 0.9\n",
            "напечатали.\n",
            "\n",
            "T = 0.9\n",
            "труго сне отоедная носора обидали. ися спорочил  учеене!\n",
            "\n",
            "T = 1.1\n",
            "еми с проволойнец не зусторался  промумит:\n",
            "ты полавлишье, уго в потом, кначу стакей чез соритаксы. он был даль. у нажей все за, телена. друг дого кателезы куплиа лече?\n",
            "\n",
            "T = 1.1\n",
            "дейка ленелось гонтилом. меже доменев насалазвхорит:\n",
            "то же потил с олским слагоголиш истью. и ходитевой канрием. но ониментал скарлатурникац. пуянии. , прозначим?\n",
            "\n",
            "T = 1.1\n",
            "моя доль, ончаталь ввоеп мах жентал отгианил д парадалачтерфей(к ну. пошицения с хогат родикся:\n",
            "контяшеваз раз нем и селиновис долака и напилить.\n",
            "\n",
            "T = 1.1\n",
            "еми толечное,  одвет лашалсяв, сказал мой. шаглегов рестул кат люсо была тольно с рабаторном мней. в солевне. что ты будель делься. хоробы. статам врихой, изняшивашь, напониц\n",
            "е. тете восаче навченсть, к покризной.\n",
            "\n",
            "T = 1.1\n",
            "наютим, затубит говодресский бойстя касконо, мыкодялся, четы хорчашь капива, ил казай.\n",
            "\n",
            "===== Epoch 30 =====\n",
            "\n",
            "T = 0.3\n",
            "да, я фронтовик.\n",
            "\n",
            "T = 0.3\n",
            "тогда я сейчас вернусь.\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.3\n",
            "что интересно?\n",
            "\n",
            "T = 0.3\n",
            "не так каказа?\n",
            "\n",
            "T = 0.5\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.5\n",
            "бывал ли пушкин в этих краях? куз исла дела была алкаранакци. какому редная затемани говорит:\n",
            "выплиния лень из не приховол в глобиный на сели какантимо мутикова сказала. значем, чето женщина. ондактыв лечный вострого бродное в мороня. тогдая спровили:\n",
            "в тема прочему на устевный малого. он был заженичный не подремны. и вольф скари леница. том ответили.\n",
            "\n",
            "T = 0.5\n",
            "я сеня был ний косьи в отер берез мне был,  акветст.\n",
            "\n",
            "T = 0.5\n",
            "какая разница?\n",
            "\n",
            "T = 0.5\n",
            "тогда я сейчас вернусь.\n",
            "\n",
            "T = 0.7\n",
            "в сказал. може да есть в посто порочился и воскто том отсказом снада. седиталатесто черовако. и том друмум, поризоли с большели столько очатебя с памина что?\n",
            "\n",
            "T = 0.7\n",
            "какая разница?\n",
            "\n",
            "T = 0.7\n",
            "бывший филолог в нем ощущался.\n",
            "\n",
            "T = 0.7\n",
            "тогда я спросил:\n",
            "комнату или шалаш?\n",
            "\n",
            "T = 0.7\n",
            "режиссер ответил:\n",
            "можно но иведно моговнор,  каздлая а когорен оваридась, чего сомудил ов. о они на мамо день рождения. они на больной меная беледуговоным воютона. пордиет,  ответил дашести пратевкись. одноже оне насчатова с самней его был весет. так на дахожи шконочила оветалься. евор лен вольф я не прошела настуют. каторабрасор? зашелится леднице. с говотел ов дест най деми. на мне нечем он приятель еля быра не приходит.\n",
            "\n",
            "T = 0.9\n",
            "затем том небольном и еми нечарден. валедале не был, дамаз?!  справиваю скашальевственнок воткес:\n",
            "а запоев аес его себя спишила на захоцило на капидная. годому коглазат. знакой лили это понеднее. и обрам леза топреситала пастаритванитый может. и так по сажиею  сень мунифитом. ого сказала резкана.\n",
            "\n",
            "T = 0.9\n",
            "спроисли к накрагда гизсомданния чустак мне сказал:\n",
            "мочну льконы и всимутки. породеки, напро от просомали пронука. с этов, дохого спровили не крей.\n",
            "\n",
            "T = 0.9\n",
            "как вас постричь?\n",
            "\n",
            "T = 0.9\n",
            "отгодари сканалось эмо  втенятсть. дот м соленакцию приблезмольен, укорой. пенявал запемное вельна.\n",
            "\n",
            "T = 0.9\n",
            "быльми ни темедо вадае?\n",
            "\n",
            "T = 1.1\n",
            "что ты думаешь насчет евреев?\n",
            "\n",
            "T = 1.1\n",
            "конечно, драматург.\n",
            "\n",
            "T = 1.1\n",
            "меня тоге с варься бедумов. и вот рутзизил в россой койменегу твохчаесь, развислею,  какорат.\n",
            "\n",
            "T = 1.1\n",
            "а как жа?\n",
            "\n",
            "T = 1.1\n",
            "(послеук:\n",
            "жень инет отвачале у на непица. дак желовали?! скоччимую этоми в лиенку. котущнал в деромей-то в нем прицетногдевной реижла жера!\n",
            "\n",
            "===== Epoch 35 =====\n",
            "\n",
            "T = 0.3\n",
            "да, я фронтовик.\n",
            "\n",
            "T = 0.3\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "я себя ужасно чувствую.\n",
            "\n",
            "T = 0.5\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.5\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.5\n",
            "я сказал:\n",
            "любимый ресторан куприна!\n",
            "\n",
            "T = 0.5\n",
            "не подулинол с расковый шукнико спрошила:\n",
            "сотиту, то посли ойначалс мелиний обудали и говорит:\n",
            "тол у вень фумыту и все.\n",
            "\n",
            "T = 0.5\n",
            "да, я фронтовик.\n",
            "\n",
            "T = 0.7\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.7\n",
            "ответил:\n",
            "мол и еля в жем не воден ве госоратурить. вых в пискуйти и болать. в тугудно страли на чере ребуднают?\n",
            "\n",
            "T = 0.7\n",
            "я зашел в два.\n",
            "\n",
            "T = 0.7\n",
            "полесмин к какатер, у вотили отпровил:\n",
            "я я бов руствы. так ужаедовна такар годнима далего. а демо равила ли е пойдет. и отвецел посиле стал. за ленино сполятильму у стали вы и прожиломона. онем водду.\n",
            "\n",
            "T = 0.7\n",
            "женда то дайта вселода. корману ленина. а такопочно малочать?! как не же думо на одец и расслииа была образалься! полизовно егоени другать. сташе монамалого сопровича:\n",
            "столь овней запемына бысарший. как-то сказала деть. что мне хочитов деленоги гобудели в девотку каза кразиманыме савелин.\n",
            "\n",
            "T = 0.9\n",
            "хрожин е драмолет. не евтерессоровского долого годурил с пашул жен. редактором радале на залидает правова не слевнор.\n",
            "\n",
            "T = 0.9\n",
            "да лю я иленьел но безепиномом была левноскин.\n",
            "\n",
            "T = 0.9\n",
            "можно ле не оте то босе да из проитова. и вор ус найдатело е буденталь он гол засли в ответ рузаниковнац и поднам молоференция трудного потодей. рыминте момнои скиратьевод е поякратов. на олен повиз ленино, как не удиково пешеним оноть забеные слишки болачели. изашую поэта быле на запахиа! серреват след он как-то вакго убидаль его была на мене прягела:\n",
            "ут болест. при лисен к этом трих аскепие. спришила дергойух. пя как назасли мое. в двуг\n",
            "\n",
            "T = 0.9\n",
            "одного стемя покрышки гоботе скомал: мерте мни встментел текого сетена резвелет?\n",
            "\n",
            "T = 0.9\n",
            "на? чара пручаовочаесь м слобенский дугки.\n",
            "\n",
            "T = 1.1\n",
            "виз от что жидатся. актавуену, раз не ужеала обитьзов не кринтеро. с битук а лего. собу и алстучес. празночатьле срамина на дерога. я не полор, постораналсь а тующ иза бредуь умореп. тотдя шашнуе  исперсли, что и приходим чесхи. аворат цал. пушел зогунитны. чубрескор все не женщина. я кутправать едудаго! черые ода на дала., здевим, говорит.\n",
            "\n",
            "T = 1.1\n",
            "прикакум се жийкт, тюрьм? на сила квил.\n",
            "\n",
            "T = 1.1\n",
            "день и тобы лю ишельный систерялся. отверил вка вепкили и несиделкая когодь доращая присдалави а гадау да а не жев. и захому же а столей. в друг, зотом. тыпе сдела техы. наапим затринакся шегран солей гудкая. жемог, афретскии кнап это произноговсониковаю потлабии толчаства драмугну. повится в:\n",
            "зательнахо жизорачноева он чао-то вогорь бралое дастая! нуша? пулищит. и боту спрасилал этакиканфичелима похарона глевнило. батей, азтенягр  звонют черотко от бело перхи т белефелся гувиния и хадиште егов\n",
            "\n",
            "T = 1.1\n",
            "научим зарабитывать!\n",
            "\n",
            "T = 1.1\n",
            "а как же вы хотите?\n",
            "\n",
            "===== Epoch 40 =====\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "полевил мроня сказала:\n",
            "мней же тво несказовал, что не летнойска. седь емоду мени елся не выстроче загогоновали в постели заглединов дели деми. голодиц!\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "не так какера?! поэту у земиником место. в сален лей дого. подужели на остеня. и вот промучу:\n",
            "столя и спросила:\n",
            "что так и серится.\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.5\n",
            "что именно?\n",
            "\n",
            "T = 0.5\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.5\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.5\n",
            "беседовали мы с пинова.\n",
            "\n",
            "T = 0.5\n",
            "какой же ты драматург?! у его попелтули.\n",
            "\n",
            "T = 0.7\n",
            "какой у него телефон? дерьм нут ленеца в резвералую. и яти попретум. ког то зобуща останивать жилостим от, были в педела дему. пордяел сому томенте. и всоветский, встой та, этость ужущенся и ответил:\n",
            "оврешевно его был я не жед. поду жен тужу не была не подную и парь.\n",
            "\n",
            "T = 0.7\n",
            "больше  никогда!\n",
            "\n",
            "T = 0.7\n",
            "полковник сказал:\n",
            "молодец!\n",
            "\n",
            "T = 0.7\n",
            "полежил ри с предаотолстворный совротиссву. моед напечатула. говорит пукниен, затри на честа причем зфетом. научив тебя все не что-то испаритвиту.\n",
            "\n",
            "T = 0.7\n",
            "какой же ты драматург?! у меня причем ту на и верее поро ничего. прочес полобой. а ясли общаралисно. почей воздумало, некеромое браннтурая бетально мурние вогорен престойния глаша! ли ы вередона мне так и посморнилси мводулись. почестванол днигация. пошел говорит. питуми шем ни часов.\n",
            "\n",
            "T = 0.9\n",
            "очень даже разумные.\n",
            "\n",
            "T = 0.9\n",
            "ну, и хоте  волителсказ проникакил.нниче вызнут:\n",
            "что азмеенится ирабовоз?\n",
            "\n",
            "T = 0.9\n",
            "да скай у оизнелих. коче сказал. можно влечил дажной уженик вогранся токтарет о попощит валонаму, так напои еднерь ухажитесть росказ берез умие мыческий в знако насскае:\n",
            "скознул мого прочер-товаят проновы. анкислен и его ребенаров. была написьш. икашки боскиа тулини. воздала, есть менех вою, прукновоской.\n",
            "\n",
            "T = 0.9\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.9\n",
            "в тугдая седениее сабегазат накреце звениле нака ростеранти. и нешил роской кого. поморнался в запомнит.\n",
            "\n",
            "T = 1.1\n",
            "как-то д скозыилса одаттаниес ондино, похубыве, сого жель телен, мы жадной любо. не жену гузавин ю в свол. ны мару левной сергинако? впрегенал говорыл нице. порича:\n",
            "стотро, могоча!\n",
            "\n",
            "T = 1.1\n",
            "верь леписельно сказал:\n",
            "ох что такреесто моем замая полоданая!  а(кожуб асливно калечные гобыватлидий. ушим вкушкил:\n",
            "стае  баздрай оздае пришевае\n",
            " семрей дольше. не два не устералить!\n",
            "\n",
            "T = 1.1\n",
            "продавец ответил:\n",
            "в хельсинки.\n",
            "\n",
            "T = 1.1\n",
            "лострочко м еги тебо здолит спросол, что , кар дой том лесытте.\n",
            "\n",
            "T = 1.1\n",
            "да, я пронов.\n",
            "\n",
            "===== Epoch 45 =====\n",
            "\n",
            "T = 0.3\n",
            "так вот. жених  от нас. день  отначил в двор. и вот постречать он подела. она на сомей деме на дахо и переданте.\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.3\n",
            "например, мерси. оден вы с паший того зашли в не пришева. это понзаломно сказала?\n",
            "\n",
            "T = 0.3\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.3\n",
            "с вотречакой с иветоп. в тут лего онна да мору, страча?\n",
            "\n",
            "T = 0.5\n",
            "больше  никогда!\n",
            "\n",
            "T = 0.5\n",
            "тогда я сейчас вернусь.\n",
            "\n",
            "T = 0.5\n",
            "проятнол в самремине говоря понима но спришивается.\n",
            "\n",
            "T = 0.5\n",
            "например, мерси. я она на обрай попозать на обеду. и тогда меня был нислидо. ибудно вожно спросила тогоденто порежинся и попроским этого было в так. поэти затромные была. акогон из если о болодой!\n",
            "\n",
            "T = 0.5\n",
            "и затем:\n",
            "такова селяви. начели ере енровитесь он болете.\n",
            "\n",
            "T = 0.7\n",
            "деньги получил?\n",
            "\n",
            "T = 0.7\n",
            "что интересно?\n",
            "\n",
            "T = 0.7\n",
            "бездарное, но родное,  заметил арьев.\n",
            "\n",
            "T = 0.7\n",
            "ну так как же?\n",
            "\n",
            "T = 0.7\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.9\n",
            "прочамуйт ответиким. а как та  дамагу, сомноро спросила:\n",
            "карожа:-то и ведила. ончастве глулочны, разсно в залинает?\n",
            "\n",
            "T = 0.9\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.9\n",
            "потко не инт. но не он  гороблявая спрашивает:\n",
            "\n",
            "T = 0.9\n",
            "ну, ении  тебя а что? верех лебсима стопим задажьеним всемище ведносте ился. сказилазый згости почей на состу.\n",
            "\n",
            "T = 0.9\n",
            "я не драматург?!\n",
            "\n",
            "T = 1.1\n",
            "я не драматург?!\n",
            "\n",
            "T = 1.1\n",
            "да, я еврой.\n",
            "\n",
            "T = 1.1\n",
            "это и есть притребив ерьем пудка. скаэтима канела  донтоми. отчеттио веченаланого мени принчивны сказлась.\n",
            "\n",
            "T = 1.1\n",
            "филиппов отвечает:\n",
            "она не пойдет, но бугол огодянсивалтей койник меня ты сришавие моска. порел такая могор плиятилесеть. корм, пздивывья! вотьго онбывил вмесе , ста да. у ужаною. выз малуштел не порзоту. конкисской-то вогрости летормине каплинан в питбевз.\n",
            "\n",
            "T = 1.1\n",
            "напечатали это весто.\n",
            "\n",
            "===== Epoch 50 =====\n",
            "\n",
            "T = 0.3\n",
            "приятное сказал.\n",
            "\n",
            "T = 0.3\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.3\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.3\n",
            "приятное сказал.\n",
            "\n",
            "T = 0.3\n",
            "так вот. жених  от нас. антила детка в дрем. беледовно причелысь евихо мнигоедский какопрастират лизмую. он был далашев, молодь вомурыт поэта шканерины. бутет когданном дражить вознал ем радовиться еста была тука расстраяница?!\n",
            "\n",
            "T = 0.5\n",
            "да, я решил больше не пить.\n",
            "\n",
            "T = 0.5\n",
            "ночью голос слышал. бетов половичали а была что-то им ним этот прондая книго делагоднай его. и подущаю с фентатькой. мерод, сказала:\n",
            "мне желы теленос.\n",
            "\n",
            "T = 0.5\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.5\n",
            "ну, а твенить,  отведалеско илего изалитьми.\n",
            "\n",
            "T = 0.5\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.7\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.7\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.7\n",
            "рожденный ползать летать не хочет!\n",
            "\n",
            "T = 0.7\n",
            "а что такое?\n",
            "\n",
            "T = 0.7\n",
            "какой у него телефон?\n",
            "\n",
            "T = 0.9\n",
            "поля линя стазала ружанае дакой да с редакцию! я говорит:\n",
            "ты обиная его удинтя его подизал я пестадате как импойтем. вы слашил:\n",
            "чистен воскраходан советский. высмутал го нешу. заучет ведов евить, и ват\n",
            "рубам спораскив ю пижелей, а тотерска. а напье мника. и на ота топерь уда на ус какимаймом ухарнываль в отпривнебо?\n",
            "\n",
            "T = 0.9\n",
            "что иненнос с жень м будет глязуднывым пуреда. ферех, аже изесть но водноро. пожудалтей.\n",
            "\n",
            "T = 0.9\n",
            "я сирел он в пестерчку. прочему тоть костит не бродсии.\n",
            "\n",
            "T = 0.9\n",
            "бисавел в онзем не хочеть мруха. поресоваи от наскайом, чалоше на обиденся и придяля бубетиче зашел фомущны. купил не умнеци.\n",
            "\n",
            "T = 0.9\n",
            "пишу,  ответил я.\n",
            "\n",
            "T = 1.1\n",
            "ток откраствиля мачко мнадиился станулал.\n",
            "\n",
            "T = 1.1\n",
            "и что тутец! а кого обиновай прителим лет.\n",
            "\n",
            "T = 1.1\n",
            "а что тубраса в немойчимь паова хатила дахажид. я тве научав и хорит! с все за я как женывачу! юешь. он был гольше.\n",
            "\n",
            "T = 1.1\n",
            "нучемы толано вазмаланикая галят ливу внючетари. а в синтя, там хорашк! педелавил стакого чло закочат поло кам:\n",
            "сюрада фудецала горызха. сошли в нем ну. одный мокный волдревикови и бортет. того с ним будеттв атли!\n",
            "\n",
            "T = 1.1\n",
            "демилиней у тат приняваю двартига одракслоскака галави:\n",
            "мый на поледный обриниковоматы, знальний! и вол обаййде бле позристех. за стам на сладистаме. с прьмелуд юго нелицу? какинся разние книгов. он блатнкк. дерефикся ледныв был такциз дит,  как-то икаког:\n",
            "назнаже тобу и посулобой. баказату, когдення еспо ни неголичиым мрочен.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dbG17S4-URo",
        "colab_type": "text"
      },
      "source": [
        "# Сложнее\n",
        "Однако будет лучше (внимание: это важный трюк в построении глубоких рекуррентных сетей!), если последующему слою подать на вход не только результат предыдущего, но и собственно входную последовательность; такая конструкция называется **skip-layer connection (связь с пропуском слоя)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRgoget09_oZ",
        "colab_type": "code",
        "outputId": "2ef87ea1-d3f8-4fd8-d85c-2d19dfb2b8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from keras.layers import concatenate, Input\n",
        "from keras.models import Model\n",
        "\n",
        "# input-1\n",
        "vec = Input(shape=(None, num_chars))\n",
        "l1 = LSTM(output_dim=128, activation='tanh', return_sequences=True)(vec)\n",
        "l1_d = Dropout(0.2)(l1)\n",
        "\n",
        "# input-2 = input-1 || output-1\n",
        "input2 = concatenate([vec, l1_d], axis=-1)\n",
        "l2 = LSTM(output_dim=128, activation='tanh', return_sequences=True)(input2)\n",
        "l2_d = Dropout(0.2)(l2)\n",
        "\n",
        "# input-3 = input-1 || output-2\n",
        "input3 = concatenate([vec, l2_d], axis=-1)\n",
        "l3 = LSTM(output_dim=128, activation='tanh', return_sequences=True)(input3)\n",
        "l3_d = Dropout(0.2)(l3)\n",
        "\n",
        "# input-dense = output-1 || output-2 || output-3\n",
        "input_d = concatenate([l1_d, l2_d, l3_d], axis=-1)\n",
        "dense3 = TimeDistributed(Dense(output_dim=num_chars))(input_d)\n",
        "output_res = Activation('softmax')(dense3)\n",
        "\n",
        "model = Model(input=vec, output=output_res)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, units=128)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, units=128)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"tanh\", return_sequences=True, units=128)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=45)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbhOGJ3E24lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer=Adam(clipnorm=1.), \n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8eHQnv60oZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"complex_model_{}.log\"\n",
        "\n",
        "cb_sampler = CharSampler(char_vectors, model, filename.format('sampler'), step=5)\n",
        "cb_logger = CSVLogger(filename.format('csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IZxo58a0oWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1832c2d-84d7-45b1-eb95-aebbe082a724"
      },
      "source": [
        "model.fit_generator(\n",
        "  generate_batch(),\n",
        "  int(len(sentences_train) / batch_size) * batch_size,   # объем X\n",
        "  nb_epoch=50, verbose=True, \n",
        "  validation_data = (X_test, y_test),\n",
        "  callbacks=[cb_logger, cb_sampler]\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 512, verbose=True, validation_data=(array([[[..., callbacks=[<keras.ca..., epochs=50)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "512/512 [==============================] - 201s 393ms/step - loss: 2.5955 - acc: 0.2286 - val_loss: 0.4574 - val_acc: 0.0592\n",
            "Epoch 2/50\n",
            "512/512 [==============================] - 200s 391ms/step - loss: 2.0893 - acc: 0.3469 - val_loss: 0.4318 - val_acc: 0.0661\n",
            "Epoch 3/50\n",
            "512/512 [==============================] - 201s 393ms/step - loss: 1.7425 - acc: 0.4516 - val_loss: 0.4422 - val_acc: 0.0651\n",
            "Epoch 4/50\n",
            "512/512 [==============================] - 201s 393ms/step - loss: 1.4395 - acc: 0.5435 - val_loss: 0.4686 - val_acc: 0.0639\n",
            "Epoch 5/50\n",
            "512/512 [==============================] - 200s 392ms/step - loss: 1.1960 - acc: 0.6150 - val_loss: 0.4973 - val_acc: 0.0645\n",
            "\n",
            "Epoch 5 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 6/50\n",
            "512/512 [==============================] - 201s 392ms/step - loss: 1.0052 - acc: 0.6691 - val_loss: 0.5264 - val_acc: 0.0627\n",
            "Epoch 7/50\n",
            "512/512 [==============================] - 201s 392ms/step - loss: 0.8771 - acc: 0.7051 - val_loss: 0.5525 - val_acc: 0.0618\n",
            "Epoch 8/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.7900 - acc: 0.7283 - val_loss: 0.5740 - val_acc: 0.0616\n",
            "Epoch 9/50\n",
            "512/512 [==============================] - 204s 398ms/step - loss: 0.7127 - acc: 0.7492 - val_loss: 0.5968 - val_acc: 0.0600\n",
            "Epoch 10/50\n",
            "512/512 [==============================] - 202s 394ms/step - loss: 0.6536 - acc: 0.7664 - val_loss: 0.6150 - val_acc: 0.0601\n",
            "\n",
            "Epoch 10 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 11/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.6075 - acc: 0.7793 - val_loss: 0.6354 - val_acc: 0.0593\n",
            "Epoch 12/50\n",
            "512/512 [==============================] - 203s 396ms/step - loss: 0.5688 - acc: 0.7898 - val_loss: 0.6566 - val_acc: 0.0599\n",
            "Epoch 13/50\n",
            "512/512 [==============================] - 201s 393ms/step - loss: 0.5358 - acc: 0.7996 - val_loss: 0.6674 - val_acc: 0.0604\n",
            "Epoch 14/50\n",
            "512/512 [==============================] - 202s 394ms/step - loss: 0.5059 - acc: 0.8077 - val_loss: 0.6851 - val_acc: 0.0605\n",
            "Epoch 15/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.4813 - acc: 0.8148 - val_loss: 0.7042 - val_acc: 0.0594\n",
            "\n",
            "Epoch 15 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 16/50\n",
            "512/512 [==============================] - 203s 396ms/step - loss: 0.4584 - acc: 0.8214 - val_loss: 0.7188 - val_acc: 0.0596\n",
            "Epoch 17/50\n",
            "512/512 [==============================] - 199s 388ms/step - loss: 0.4378 - acc: 0.8271 - val_loss: 0.7242 - val_acc: 0.0591\n",
            "Epoch 18/50\n",
            "512/512 [==============================] - 200s 391ms/step - loss: 0.4225 - acc: 0.8318 - val_loss: 0.7436 - val_acc: 0.0597\n",
            "Epoch 19/50\n",
            "512/512 [==============================] - 201s 393ms/step - loss: 0.4071 - acc: 0.8359 - val_loss: 0.7492 - val_acc: 0.0595\n",
            "Epoch 20/50\n",
            "512/512 [==============================] - 203s 396ms/step - loss: 0.3929 - acc: 0.8403 - val_loss: 0.7717 - val_acc: 0.0576\n",
            "\n",
            "Epoch 20 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 21/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.3801 - acc: 0.8439 - val_loss: 0.7798 - val_acc: 0.0583\n",
            "Epoch 22/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.3682 - acc: 0.8478 - val_loss: 0.7872 - val_acc: 0.0586\n",
            "Epoch 23/50\n",
            "512/512 [==============================] - 202s 394ms/step - loss: 0.3555 - acc: 0.8517 - val_loss: 0.8004 - val_acc: 0.0595\n",
            "Epoch 24/50\n",
            "512/512 [==============================] - 203s 396ms/step - loss: 0.3469 - acc: 0.8542 - val_loss: 0.8119 - val_acc: 0.0590\n",
            "Epoch 25/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.3397 - acc: 0.8562 - val_loss: 0.8165 - val_acc: 0.0590\n",
            "\n",
            "Epoch 25 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 26/50\n",
            "512/512 [==============================] - 204s 399ms/step - loss: 0.3311 - acc: 0.8585 - val_loss: 0.8252 - val_acc: 0.0593\n",
            "Epoch 27/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.3234 - acc: 0.8613 - val_loss: 0.8356 - val_acc: 0.0596\n",
            "Epoch 28/50\n",
            "512/512 [==============================] - 204s 399ms/step - loss: 0.3169 - acc: 0.8630 - val_loss: 0.8353 - val_acc: 0.0611\n",
            "Epoch 29/50\n",
            "512/512 [==============================] - 203s 396ms/step - loss: 0.3114 - acc: 0.8646 - val_loss: 0.8465 - val_acc: 0.0589\n",
            "Epoch 30/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.3053 - acc: 0.8668 - val_loss: 0.8698 - val_acc: 0.0582\n",
            "\n",
            "Epoch 30 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 31/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.2966 - acc: 0.8696 - val_loss: 0.8633 - val_acc: 0.0588\n",
            "Epoch 32/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.2937 - acc: 0.8704 - val_loss: 0.8623 - val_acc: 0.0594\n",
            "Epoch 33/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.2868 - acc: 0.8726 - val_loss: 0.8703 - val_acc: 0.0597\n",
            "Epoch 34/50\n",
            "512/512 [==============================] - 202s 394ms/step - loss: 0.2820 - acc: 0.8737 - val_loss: 0.8673 - val_acc: 0.0601\n",
            "Epoch 35/50\n",
            "512/512 [==============================] - 202s 394ms/step - loss: 0.2786 - acc: 0.8745 - val_loss: 0.8817 - val_acc: 0.0588\n",
            "\n",
            "Epoch 35 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 36/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.2734 - acc: 0.8765 - val_loss: 0.8859 - val_acc: 0.0584\n",
            "Epoch 37/50\n",
            "512/512 [==============================] - 203s 397ms/step - loss: 0.2688 - acc: 0.8777 - val_loss: 0.8976 - val_acc: 0.0586\n",
            "Epoch 38/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.2662 - acc: 0.8788 - val_loss: 0.8965 - val_acc: 0.0587\n",
            "Epoch 39/50\n",
            "512/512 [==============================] - 202s 394ms/step - loss: 0.2619 - acc: 0.8799 - val_loss: 0.8897 - val_acc: 0.0593\n",
            "Epoch 40/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.2580 - acc: 0.8813 - val_loss: 0.8970 - val_acc: 0.0587\n",
            "\n",
            "Epoch 40 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 41/50\n",
            "512/512 [==============================] - 203s 396ms/step - loss: 0.2550 - acc: 0.8818 - val_loss: 0.9104 - val_acc: 0.0597\n",
            "Epoch 42/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.2516 - acc: 0.8831 - val_loss: 0.9015 - val_acc: 0.0596\n",
            "Epoch 43/50\n",
            "512/512 [==============================] - 204s 398ms/step - loss: 0.2496 - acc: 0.8836 - val_loss: 0.9018 - val_acc: 0.0611\n",
            "Epoch 44/50\n",
            "512/512 [==============================] - 203s 396ms/step - loss: 0.2466 - acc: 0.8847 - val_loss: 0.8998 - val_acc: 0.0598\n",
            "Epoch 45/50\n",
            "512/512 [==============================] - 202s 395ms/step - loss: 0.2450 - acc: 0.8852 - val_loss: 0.9122 - val_acc: 0.0593\n",
            "\n",
            "Epoch 45 text sampling:\n",
            "\tsampling, T = 0.3...\n",
            "\tsampling, T = 0.5...\n",
            "\tsampling, T = 0.7...\n",
            "\tsampling, T = 0.9...\n",
            "\tsampling, T = 1.1...\n",
            "Epoch 46/50\n",
            " 53/512 [==>...........................] - ETA: 2:32 - loss: 0.2322 - acc: 0.8912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-e7da306652d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_sampler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1D044hI0oSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "326a5e47-79d6-4bbe-ce7b-d3209ac3fed1"
      },
      "source": [
        "with open('complex_model_sampler.log') as fin:\n",
        "  print(fin.read())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===== Epoch 5 =====\n",
            "\n",
            "T = 0.3\n",
            "в ответ прозвучало:\n",
            "привет, адольф!\n",
            "\n",
            "T = 0.3\n",
            "да, я фронтовик.\n",
            "\n",
            "T = 0.3\n",
            "тогда я сейчас вернусь. вос поприлиниц криковуки себиделся обрательно сказал:\n",
            "мом были евь. и на деле не ответил:\n",
            "одна же погде не все тратве проковались и я будетули мо себераним отразился на были за болакого. поворил белогов и ветул и проворил обнать ленина. продела теля на прашева. обрать в одноманти они пойдетел лостань в там середал молодов и вольфе шил неце деть. молодов говорил:\n",
            "ени его обинил за костинил виковил они пожелиста.\n",
            "\n",
            "T = 0.3\n",
            "я с брайте доблавал в этом тро как и содился в двалиний. и тобе долого спрашивает:\n",
            "том совешь накомил и того разницайтенный соморни. попросил его не голько стали бы вас пошказ день родуки.\n",
            "\n",
            "T = 0.3\n",
            "так вот жених  от нах. дель и удакавился:\n",
            "кареше в ответ привесил:\n",
            "и того вы ленительно соредиковора наповали в твентих крахтарант.\n",
            "\n",
            "T = 0.5\n",
            "как вас постричь?\n",
            "\n",
            "T = 0.5\n",
            "не пойду,  говорит,  какой-то он советский.\n",
            "\n",
            "T = 0.5\n",
            "когда ты хороша ? глядин так начульновича?\n",
            "\n",
            "T = 0.5\n",
            "тогда я сейчас вернусь. оторое сказал:\n",
            "голодиц вишел, захаливаль! в ходи у говорит:\n",
            "как вос посовится и выслушали, мородиная бы мой. и в этом пореслорались бы пошу, что вы на говорит!\n",
            "\n",
            "T = 0.5\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.7\n",
            "на что такое?\n",
            "\n",
            "T = 0.7\n",
            "дого вы попревил в золятец и того собы. колстово бразле не? писетели огдо. со молой. выхажили запью до мой другомное не постредно! сержал! а мелефи!\n",
            "\n",
            "T = 0.7\n",
            "да той,  обаней ловоч. биду богались меняи верью насчет нева дотомориз говорит:\n",
            "ениче товериса ер двакцан рамоестьсто молодовые сполова.\n",
            "\n",
            "T = 0.7\n",
            "я на восьте едниго расторучин скоровал. все любительно?\n",
            "\n",
            "T = 0.7\n",
            ", я ты драматург?!\n",
            "\n",
            "T = 0.9\n",
            "какая разница  почему? не седе пострейчем боле ответил захожитось, болько так. повдругстуе. кончако онабались вастону.\n",
            "\n",
            "T = 0.9\n",
            "и пошле не дель. растеля и суалибывшился этого поробыла. то дажа в спернила тоста, сордного выперил ахода.\n",
            "\n",
            "T = 0.9\n",
            "мача откузался:\n",
            "на билетнова сманите, каком-то обудали масарьшева. оденщай  верей, умостый кардулся поэту поголачный чевсевича? кричтур раз дострочко:\n",
            "торади мену в кго задоват с вождоник порессири. обя еву женио болетор толкно забрачился вневный выпил я свечевикисом по риковобулся.\n",
            "\n",
            "T = 0.9\n",
            "наумино и вось и ний полое. смол не бядесний кало обрачно скожли:\n",
            "что табу расстахит? варем курам, на ухмерский. верчего повали ла анкепрси. а то сужавал шего набующиза как-то морощее смрулиль! до все может вылигали ткапран из затанинацзы!\n",
            "\n",
            "T = 0.9\n",
            "ростика ответил:\n",
            "не воть и мон, недально и васкобобедень по-тругону. от ах и орновает поньмого случил говорит:\n",
            "вонь и как-то ибесебялись.\n",
            "\n",
            "T = 1.1\n",
            "топоро себор дудь. и моеги люяди, молоднив колчео:\n",
            "зжават сежя вышну серевая уерьу. зошника опресумист). и ема желадной навозщевала с менниценко питело найман. иму. тук напринельном кореденьом моя полчанывшиваес?!). я вочьи фожуля и бужеловно минчи.\n",
            "\n",
            "T = 1.1\n",
            "подка-то был  говорит:\n",
            "нада же пы вотренил вос татнольной удималим!  как писол иделевдру грускину:\n",
            "а врегц певольмах гидутка стрател даска судажкое повыны вридица!\n",
            "\n",
            "T = 1.1\n",
            "мате же головелись маяту, мяя жевнудлсяи ни пойдет и колкурон пелолиз. с драматург! ка учто так е-бу сосликои врогу! днуг жи нут?\n",
            "\n",
            "T = 1.1\n",
            "удсим пойлико ! вдруг хер лювантыя ублисига напро изоронее в легогу. вольфи одя было жен-кого-ту имлюров. обона в засели умужный гости был финковуркие это дорогаяя момта. при тону бы они тракой. вет ну балеть манкомат вы какое.\n",
            "\n",
            "T = 1.1\n",
            "я когду ро слушал молять, хорошив п впослей. увили салавишко, зножиниковом олфроком, была жень кручитруе  научался на. обратнов жедита по хороши. ботер, хоряши мапаеб, в дву, и яхоров. от помосил и имебя, выс упле коподники в глед. идельфовис вортуеноста не позвозовили.\n",
            "\n",
            "===== Epoch 10 =====\n",
            "\n",
            "T = 0.3\n",
            "ну, а все-таки, что он сказал?\n",
            "\n",
            "T = 0.3\n",
            "тот же голос произнес:\n",
            "стоп! я выхожу.\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "пожалуйста.\n",
            "\n",
            "T = 0.3\n",
            "беседовали мы с пановой.\n",
            "\n",
            "T = 0.5\n",
            "больше  никогда!\n",
            "\n",
            "T = 0.5\n",
            "демиденко отвечает:\n",
            "нет часов.\n",
            "\n",
            "T = 0.5\n",
            "напечатали.\n",
            "\n",
            "T = 0.5\n",
            "как отчество младшего сына а.с.пушкина?\n",
            "\n",
            "T = 0.5\n",
            "не за что!  роняет вольф и удаляется.\n",
            "\n",
            "T = 0.7\n",
            "например, мерси. несил я верем снима. обратнол. и проятной в зацензий остьеникоголаробо. говорит,  паши мне индерде.\n",
            "\n",
            "T = 0.7\n",
            "вольф подумал и тихо говорит:\n",
            "если так, расскажите намо леспер.\n",
            "\n",
            "T = 0.7\n",
            "не за что!  роняет вольф и удаляется.\n",
            "\n",
            "T = 0.7\n",
            "режим: наелись и лежим.\n",
            "\n",
            "T = 0.7\n",
            "продукаковог ответил павать ленинандрин кразу. литова деладмо погубини в говсил тебе. разсовит фидцавнос помурчали в неше. голос произнесит:\n",
            "я вы не перега, оне сома чум дело.\n",
            "\n",
            "T = 0.9\n",
            "нева? что вдруг?!\n",
            "\n",
            "T = 0.9\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.9\n",
            "дедиг ботольмился дваркя не попвостлували, что таки: фума\"и. произнесителья осказал. почем вату даксимия сферчателий! сем-ни спрашивает:\n",
            "как это иму семуро? начена волиса не продстий. очно так емо гоздожевать. в сел меняй.\n",
            "\n",
            "T = 0.9\n",
            "то есть люди одной с ним продессии.\n",
            "\n",
            "T = 0.9\n",
            "и пли накогович онериделя. означил в пиль емудрился. это он говорил:\n",
            "за оже бей мой не затем. вольф и я обадался.\n",
            "\n",
            "T = 1.1\n",
            "никакого,  говорю.\n",
            "\n",
            "T = 1.1\n",
            "писатели вольф скрал фернова. звал мне одчатовь с женихорань.\n",
            "\n",
            "T = 1.1\n",
            "и весто ленин. и тюбо протостелся в даней гости. и есть в летом в имоле где здажете. совнет анденовым пенеьзами.\n",
            "\n",
            "T = 1.1\n",
            "однажды меня приняли за курана то посты.\n",
            "\n",
            "T = 1.1\n",
            "моя было быльше кникагу не зущекнала ле не выс быт в таоткрскмина кортактоер сказал:\n",
            "адем жестраниты манмашь мне меня прялся. затом стажила раблую, напристе. не делобой. очете бозвет вольча друг день. смотрял загор пошу, что ну уемья. мусслушься, гудит вом пус рекатуром.\n",
            "\n",
            "===== Epoch 15 =====\n",
            "\n",
            "T = 0.3\n",
            "что именно вас не устраивает?\n",
            "\n",
            "T = 0.3\n",
            "да так, порадовал меня.\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "приятное сказал.\n",
            "\n",
            "T = 0.5\n",
            "режиссер ответил:\n",
            "можно но плавной продазгу. с васимуная с авсейшем. одиски варману. говорит ему просли и встогляли с ответне:\n",
            "парушки собались дух. терека спрошиваюа асковорнило чаловека?\n",
            "\n",
            "T = 0.5\n",
            "приятное сказал.\n",
            "\n",
            "T = 0.5\n",
            "беседовали мы с пановой.\n",
            "\n",
            "T = 0.5\n",
            "мог бы наполеон стать учителем фехтования?\n",
            "\n",
            "T = 0.5\n",
            "ну, хотя бы приблизительно?\n",
            "\n",
            "T = 0.7\n",
            "приятное сказал.\n",
            "\n",
            "T = 0.7\n",
            "моя жена говорит:\n",
            "нойма, бойдет врамоткого что-то защешка моего поднавить?\n",
            "\n",
            "T = 0.7\n",
            "я сказал:\n",
            "любимый ресторан куприна!\n",
            "\n",
            "T = 0.7\n",
            "мого понавилось даже неомоза ит поста.\n",
            "\n",
            "T = 0.7\n",
            "что именно вас не устраивает?\n",
            "\n",
            "T = 0.9\n",
            "шагал в ответ:\n",
            "не похоже.\n",
            "\n",
            "T = 0.9\n",
            "да, я фронтовик.\n",
            "\n",
            "T = 0.9\n",
            "обычное вопросные. кота ты волкон из есть бетет. вледию маленицерестора кничала педеря. а том совсял пьему таково на судетим вальфации зама иразают сказа волобо!\n",
            "\n",
            "T = 0.9\n",
            "не за что!  роняет вольф и удаляется.\n",
            "\n",
            "T = 0.9\n",
            "да так, порадовал меня. суде по ульцеи вомути. страчил чень подавлица?!\n",
            "\n",
            "T = 1.1\n",
            "театр абсурда. пьеса: в ожниденинаго занет. тапен намочнулся хочестую. печетать это оздановой понтиз стреченам муры. накоморо: такой тах иглавочно. дала попров кулячници в довейцая верхым сободником!\n",
            "\n",
            "T = 1.1\n",
            "грубин в молько изначилось бозьюриза вамаго на педа).\n",
            "\n",
            "T = 1.1\n",
            "члены комиссии вздрогнули и переглянулись.\n",
            "\n",
            "T = 1.1\n",
            "фиртол сказал:\n",
            "молой отверкие при леннизал добавко спрасивает очтень расся доен жерграниты. и жена бы обстойтей в зашел. думали раштего в плавадние комалисти в лентках с стахорбать. я уппевся талином. на удиставовсли говорят:\n",
            "толка совели тредью мочетенному замонить?!\n",
            "\n",
            "T = 1.1\n",
            "рас отретали моег подначил:\n",
            "недажды, мерта кревое они вы пах. женим задя. а вот поднаго по-мудующим!\n",
            "\n",
            "===== Epoch 20 =====\n",
            "\n",
            "T = 0.3\n",
            "приятное сказал.\n",
            "\n",
            "T = 0.3\n",
            "тогда я сейчас вернусь. подит меняце.\n",
            "\n",
            "T = 0.3\n",
            "в ответ прозвучало:\n",
            "а как ты можешь носить орден покойника?!\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "да, я фронтовик.\n",
            "\n",
            "T = 0.5\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.5\n",
            "филиппов отвечает:\n",
            "она не пойдет. но лачно вам она понравилась?\n",
            "\n",
            "T = 0.5\n",
            "у поэта шестинского была такая строчка:\n",
            "она нахмурила свой узенький лобок\n",
            "\n",
            "T = 0.5\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.5\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.7\n",
            "тетка догнала его и спрашивает:\n",
            "\n",
            "T = 0.7\n",
            "найман и бродский шли по ленинграду. дело было ночью.\n",
            "\n",
            "T = 0.7\n",
            "да, я фронтовик.\n",
            "\n",
            "T = 0.7\n",
            "что ты думаешь насчет евреев?\n",
            "\n",
            "T = 0.7\n",
            "что ты думаешь насчет евреев?\n",
            "\n",
            "T = 0.9\n",
            "слышу от инги петкевич:\n",
            "раньше я не подозревала\n",
            "\n",
            "T = 0.9\n",
            "а что такое?\n",
            "\n",
            "T = 0.9\n",
            "я себя ужасно чувствую.\n",
            "\n",
            "T = 0.9\n",
            "какая разница?\n",
            "\n",
            "T = 0.9\n",
            "тогда я сейчас вернусь. и пой ней жем дедоловый друголюриван рез причем у астематворовся быший рокопычи:\n",
            "коткого, свенала дума канина фольут.\n",
            "\n",
            "T = 1.1\n",
            "розве не следа. с втум на често личшесть.\n",
            "\n",
            "T = 1.1\n",
            "так вот. жених  от нас. глусициров может назоваться в ожененилский.\n",
            "\n",
            "T = 1.1\n",
            "шле тогда втремось мой форбости на друсственин?\n",
            "\n",
            "T = 1.1\n",
            "это подействовало даже на советских чиновников.\n",
            "\n",
            "T = 1.1\n",
            "бы сонй отпрывился на сподните. ихдер головился. бы моляте. подумает, чего розделся в тамонтывескую пой алисно.\n",
            "\n",
            "===== Epoch 25 =====\n",
            "\n",
            "T = 0.3\n",
            "я сказал:\n",
            "любимый ресторан куприна!\n",
            "\n",
            "T = 0.3\n",
            "не за что!  роняет вольф и удаляется.\n",
            "\n",
            "T = 0.3\n",
            "моя жена спросила арьева:\n",
            "андрей, я не пойму, ты куришь?\n",
            "\n",
            "T = 0.3\n",
            "что именно?\n",
            "\n",
            "T = 0.3\n",
            "что интересно?\n",
            "\n",
            "T = 0.5\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.5\n",
            "то есть люди одной с ним профессии.\n",
            "\n",
            "T = 0.5\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.5\n",
            "я себя ужасно чувствую.\n",
            "\n",
            "T = 0.5\n",
            "тогда я сейчас вернусь. из поголучный людой. клонной в гли не как есть?\n",
            "\n",
            "T = 0.7\n",
            "что интересно?\n",
            "\n",
            "T = 0.7\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.7\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.7\n",
            "не за что!  роняет вольф и удаляется.\n",
            "\n",
            "T = 0.7\n",
            "все молчат.\n",
            "\n",
            "T = 0.9\n",
            "у точересто он закоматся в прокозноценной довели неду и говорит:\n",
            "а, говорят, выйну, ты пихают сать буховова, менят.\n",
            "\n",
            "T = 0.9\n",
            "еврей полумие. ствитление дравнога. соволил и выглубитель по ис немина крике вотку. произдемного ресторая. значим тет юма сула одного еврея. он поже увиется дела.\n",
            "\n",
            "T = 0.9\n",
            "я. а как жео все потите своича дестубристици. почеление сно обстровова с лосциюнной жизна чироско. спрашиваю:\n",
            "спо-за на тогорины, погдама жевшей, на соврещей дельма.\n",
            "\n",
            "T = 0.9\n",
            "напучатали. восью маленацы. сидя сепяшнее покомную?\n",
            "\n",
            "T = 0.9\n",
            "бродский перебил его:\n",
            "это в том смысле, что просидел шестнадцать лет от звонка до звонка?!\n",
            "\n",
            "T = 1.1\n",
            "да,  говорю,  однако сам еще не прочел. что же на сочееня истови. снадлуник в дутка. сиду  нашей-то пожайти. брит за ходишь воднули и того редак. и соменнит дак.\n",
            "\n",
            "T = 1.1\n",
            "не за что!  роняет вольф и удаляется.\n",
            "\n",
            "T = 1.1\n",
            "убийца пожелал остаться безескунами. причествую каницию.\n",
            "\n",
            "T = 1.1\n",
            "судь и васуднилисьвиз говорит:\n",
            "твою\n",
            "как подумает. напьнегаласо на протовачю о закомы питестьем удила заднит, порестал какомной. вы вал. пидяте любоего еврадоваешь достает цебказывали с юрой:\n",
            "и если малошь. ему последние скора верегал, что я нема спохоратвераю невей жали но дочете.\n",
            "\n",
            "T = 1.1\n",
            "я говорю:\n",
            "неужели ты хорошо серя кужде желию\n",
            "не так жена ни обста таклифноми. ичен вот однажды поэт мушкин. мо коромер!\n",
            "\n",
            "===== Epoch 30 =====\n",
            "\n",
            "T = 0.3\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.3\n",
            "шагал в ответ:\n",
            "не похоже.\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.3\n",
            "что интересно?\n",
            "\n",
            "T = 0.5\n",
            "ну, а все-таки, что он сказал?\n",
            "\n",
            "T = 0.5\n",
            "я удивился и пошел домой.\n",
            "\n",
            "T = 0.5\n",
            "что интересно?\n",
            "\n",
            "T = 0.5\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.5\n",
            "тогда я сейчас вернусь. зашей подмару гляниту квез тво молчано продавстое летовая моленая на говорит:\n",
            "какай фума рав невелом, начто ему протавол. разоне старила взализм, пананы молбогол. кдал выпел на как-то в развертенной шал а. спавнойне. ты прехорашие гольфо:\n",
            "плав семину совется и так даселеву. он сказал:\n",
            "вольфу мой драм тразать в дразки из того наптином. каконе дувелениций за говорит:\n",
            "я убей вали помой. тогда вы но значным массымы срибали. прибыла у выплинат учительный добравали на засемони\n",
            "\n",
            "T = 0.7\n",
            "в советских газетах только опечатки правдивы. пустому челоку день имуров, кого он был алешь?\n",
            "\n",
            "T = 0.7\n",
            "пришел к нам арьев. выпил лишнего. курил, роняя пепел на брюки.\n",
            "\n",
            "T = 0.7\n",
            "режиссер ответил:\n",
            "можно но плавно встречалось можит бетовались на раздорныва ная не ростариловский мояг, а крапивного разнего отел. ты молять, сульту высну, когдано закомой филнот месте не любой. еще блавой с этой подема с най. накануество. заледи у пектаривела начился такои с нашла доевое, и того бой именя союра спорожали, в там и голодом. и говорит:\n",
            "он, мажи случил большей молят.\n",
            "\n",
            "T = 0.7\n",
            "тогда я сейчас вернусь. зашей нековышка. ответил презвонит:\n",
            "найдо же эрим не устроил садашли, мудов,  и это полого она был зажитанич!\n",
            "\n",
            "T = 0.7\n",
            "стали знадомого поднеко на отиденивского. стово навчесте и тебе долса тре каканулся попут. чираз так фронтомождый можалка. причет вмего сонникомна у меня а гостера лету. выли на сепкендер. однако мне гласодорным поэта докомжено:\n",
            "трезную моего намоприсила двастетка скразали:\n",
            "мне же таковал федущини. в тот грубин с остахи?! все молчат.\n",
            "\n",
            "T = 0.9\n",
            "тот же голос произнес:\n",
            "стоп! я выхожу.\n",
            "\n",
            "T = 0.9\n",
            "в ответ одразалось пои босодния попул тагнинци. видушника с ней прохожи! вочно поздаше, чеховара есть, когда его безданат, резна изонка. мостаку слешу кругину. в льмунастом с ветремухам. жевенял отстая. с ней започный емушь. образне написать вдругы.\n",
            "\n",
            "T = 0.9\n",
            "хорошие. но мало.\n",
            "\n",
            "T = 0.9\n",
            "да так, порадовал меня. с юрь евой жилисати всемодная лет. произнес:\n",
            "ты ошибаешься. это не букет. это  венок.\n",
            "\n",
            "T = 0.9\n",
            "с вотом чусская пареващай. порика:\n",
            "соверниленной и тихо он запись вы митом рукство нереча трудались горовой говорит:\n",
            "ну, мое пыкта. ты конь обинать лодном и срадил мого. фратновом полжен собратова и говорит:\n",
            "обнайда я бевровичься. тесене, наконацую мор, не похожита драматург.\n",
            "\n",
            "T = 1.1\n",
            "ну сказал:\n",
            "вольфе собрательно миночи. одного мопор заместе в гразнин:\n",
            "как и тебе диль поста и а нападаща драгору?!\n",
            "\n",
            "T = 1.1\n",
            "река руж полоднико в этипепени толятки.\n",
            "\n",
            "T = 1.1\n",
            "мне? ничего!\n",
            "\n",
            "T = 1.1\n",
            "однако маме не сказал. зачем?\n",
            "\n",
            "T = 1.1\n",
            "витом  спрасила хорут:\n",
            "товорищ шекний возвет фрунтова и говорют:\n",
            "кома,  ответил, чаловек монет бексизанчики попасадились.\n",
            "\n",
            "===== Epoch 35 =====\n",
            "\n",
            "T = 0.3\n",
            "да, я еврей.\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "напечатали.\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.5\n",
            "как вас постричь?\n",
            "\n",
            "T = 0.5\n",
            "то есть, как это советский? вы ошибаетесь!\n",
            "\n",
            "T = 0.5\n",
            "вольф подумал и тихо говорит:\n",
            "если так, расскажите нам о себе.\n",
            "\n",
            "T = 0.5\n",
            "моя дочка говорила:\n",
            "я тое бибиси на окно переставила. и тут долье слишки оподнаст лет.\n",
            "\n",
            "T = 0.5\n",
            "что интересно?\n",
            "\n",
            "T = 0.7\n",
            "тетка догнала его и спрашивает:\n",
            "\n",
            "T = 0.7\n",
            "мемориальная доска:\n",
            "архитектор расстрелян.\n",
            "\n",
            "T = 0.7\n",
            "так вот. жених  от нас. дять посил три дак.\n",
            "\n",
            "T = 0.7\n",
            "хорошие. но мало.\n",
            "\n",
            "T = 0.7\n",
            "случилось это в таллине. понадобилась мне застежка. из тех, что называются молнии. захожу в лавку:\n",
            "молнии есть?\n",
            "\n",
            "T = 0.9\n",
            "ну, хотя бы приблизительно?\n",
            "\n",
            "T = 0.9\n",
            "пишу,  ответил я.\n",
            "\n",
            "T = 0.9\n",
            "тетка догнала его и спрашивает:\n",
            "\n",
            "T = 0.9\n",
            "и все подтвердили, что глаза ленины.\n",
            "\n",
            "T = 0.9\n",
            "больше  никогда!\n",
            "\n",
            "T = 1.1\n",
            "тру, на есть ледино призовит садь квончел звонить. это говорил обарье. напимает издровой все долуга туфет.\n",
            "\n",
            "T = 1.1\n",
            "псевдонимы: михаил юрьевич вермутов, шолохов-алейхем.\n",
            "\n",
            "T = 1.1\n",
            "я зашел в два.\n",
            "\n",
            "T = 1.1\n",
            "чирсков принес в редакцию дука. прочьные стол голос:\n",
            "мы, четы вадешь ейба иденжевнястью. тем алиментов рестрочный зашли напека естисла онин стретки. мотги отпровиться наждысную. втритный как изалинский пошлинали. он стопол в обставеленной дамо больфон это судают вомуравение законтичелсяю. поволис предолись  к смолой. и вотратопь с сочей бокисту.\n",
            "\n",
            "T = 1.1\n",
            "никакого,  говорю.\n",
            "\n",
            "===== Epoch 40 =====\n",
            "\n",
            "T = 0.3\n",
            "не за что!  роняет вольф и удаляется.\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.3\n",
            "однако похожим быть хочется только на чехова. сотвеня долного врадительно  прошазнил. в смое протыв ответный дострова глашка отенчать прочес ленинару. кутер, а заявила чарьно в кометки. ком отора сказала писеле у некой дунька. она не подорег!\n",
            "\n",
            "T = 0.5\n",
            "напечатали.\n",
            "\n",
            "T = 0.5\n",
            "я сказал:\n",
            "любимый ресторан куприна!\n",
            "\n",
            "T = 0.5\n",
            "в пострушком голости повожил веница. стретник орженся нашал смостел. что же он тоге на седели вольфа семяю невельна даре пошула. ов залевиц у меня причет варушой говорит:\n",
            "райно была ленина догу, кротику по заневалимой делекоробы. убялись и подел, вольф и удреже нейман отимется. кличны в приятере судал деньги в окфор:\n",
            "тену то жена. ставил в ресторан говроят смажили спративать так за муна как еврее?\n",
            "\n",
            "T = 0.5\n",
            "в ответ прозвучало:\n",
            "а как ты можешь носить орден покойника?!\n",
            "\n",
            "T = 0.5\n",
            "тогда я сейчас вернусь. подивал обратили не попровича серьев дворните. вмейну приглашнова собера непеса такимы. вольф еду, мол дарнел сомоть в редакцию. в молекси сверен саматер:\n",
            "тома соверски  это малошь имен, минка. он в гостя как-то устрось воскобую постуди в груских с сфирател. я разум. вы напочит с меломучко. тамо навчем тудель раз овстова. и дале были е том польконыму пельцио! так и я нестала выскулан?\n",
            "\n",
            "T = 0.7\n",
            "случилось это в таллине. понадобилась мне застежка. из тех, что называются молнии. захожу в лавку:\n",
            "молнии есть?\n",
            "\n",
            "T = 0.7\n",
            "шагал в ответ:\n",
            "не похоже.\n",
            "\n",
            "T = 0.7\n",
            "и тогда валера ответил:\n",
            "опротивела!\n",
            "\n",
            "T = 0.7\n",
            "приятное сказал.\n",
            "\n",
            "T = 0.7\n",
            "затем вынимает из тайника маленькую.\n",
            "\n",
            "T = 0.9\n",
            "я себя ужасно чувствую.\n",
            "\n",
            "T = 0.9\n",
            "арьев говорил:\n",
            "в нашу эпоху капитан лебядкин стал бы майором. пишел а восмонкле. вы доль о чем дено разнаетимой. говорит:\n",
            "зашей вопрон, чно в зомети. погостерга вольфон судь обрамое. в молодую при не отпеталься на сказал:\n",
            "мол дек, раз приян тебиль комунки. сидья в балене свотрете, что хорога ставлич. да его ростакти. накутнов,  отчентво приблемное словались. подели, чтобы в этой долень родитель от просвали с он андислей.\n",
            "\n",
            "T = 0.9\n",
            "в ответ прозвучало:\n",
            "а как ты можешь носить орден покойника?!\n",
            "\n",
            "T = 0.9\n",
            "филиппов отвечает:\n",
            "она не пойдет. но лично вам она понравилась?\n",
            "\n",
            "T = 0.9\n",
            "однако похожим быть хочется только на чехова. смотри вожел они настретния. казываю мне был холошей с бельниче. шам он был. звоет тога день говорит:\n",
            "мно билинное моег умород. авиреза дель ректирую свозила может. однакойне я не опидать в окназнали. они то его спрашивает:\n",
            "ну, как рести? показаться в далсагрузительно?\n",
            "\n",
            "T = 1.1\n",
            "начаго вы лашиете на городой, домозват, польков не сведающия. дайка с серядали пурег антубрату. жевеки не плигуталиный?\n",
            "\n",
            "T = 1.1\n",
            "разщенит вронстразниваться открузваенты в просторениковобресто летмонские эрока более в зеалка. повеслу ленино вы иму желасит чалостовен подоромники за редере. он так далее. вотим в окстовке еврей прикорину.\n",
            "\n",
            "T = 1.1\n",
            "бейно  видет летать и востоблетней неабраховника порадцетелься в  восемь снушко отимется. извъешил чиновние я разговор в постайте всегонни в имее годиналом. потем у веселкатно. стручал забрачатые на. а воймо этой поем будеречасно.\n",
            "\n",
            "T = 1.1\n",
            "полковник сказал:\n",
            "молодец!\n",
            "\n",
            "T = 1.1\n",
            "у молгодил слышул с ахмат. листровов пяшли одного евредого. в молю произнасили оч агде. затров. ок уна копочнителься домет.\n",
            "\n",
            "===== Epoch 45 =====\n",
            "\n",
            "T = 0.3\n",
            "дело было в пивной. привязался ко мне незнакомый алкаш.\n",
            "\n",
            "T = 0.3\n",
            "причем тут наждак?\n",
            "\n",
            "T = 0.3\n",
            "напечатали рассказ?\n",
            "\n",
            "T = 0.3\n",
            "какой же ты драматург?!\n",
            "\n",
            "T = 0.3\n",
            "почему же они молчат? почему контактов не устанавливают?\n",
            "\n",
            "T = 0.5\n",
            "однажды меня приняли за куприна. дело было так.\n",
            "\n",
            "T = 0.5\n",
            "ленин произносил:\n",
            "гавнодушие. ене подзавали в заявил:\n",
            "учень в один ментиюсть. зашей наконел бумого. подали за пошу, конать отчет лего фотс дрегаловени мать на естакиетля. ответил мога фировал они понравилось она на рассказил:\n",
            "мнего лет не да. еду по затем недого!\n",
            "\n",
            "T = 0.5\n",
            "пожалуйста.\n",
            "\n",
            "T = 0.5\n",
            "можно ли носом стирать карандашные записи?\n",
            "\n",
            "T = 0.5\n",
            "в ленинграде есть комиссия по работе с молодыми авторами. вызвали на заседание этой комиссии моего приятеля и спрашивают:\n",
            "как это мость это и есть будетевском нетриктря. польчины вогосто плексимается, вном личен еду. летой звончила начеласту. произнелю молодый с прибоникал:\n",
            "одень редпкревнае они разопиться. часовенский писатель забитиле надельно сказал:\n",
            "мон одиние смотрит. в отем поседил в дрегрый у томарулся. ты полет гостровали мне интересно.\n",
            "\n",
            "T = 0.7\n",
            "а как же вы хотите?\n",
            "\n",
            "T = 0.7\n",
            "в ответ прозвучало:\n",
            "привет, адольф!\n",
            "\n",
            "T = 0.7\n",
            "а как же вы хотите?\n",
            "\n",
            "T = 0.7\n",
            "пришел к нам арьев. выпил лишнего. курил, роняя пепел на брюки.\n",
            "\n",
            "T = 0.7\n",
            "валерий грубин  тане юдиной:\n",
            "как ни позвоню, вечно ты сердишься. вечно говоришь, что уже половина третьего ночи.\n",
            "\n",
            "T = 0.9\n",
            "мне? ничего!\n",
            "\n",
            "T = 0.9\n",
            "тогда я спросил:\n",
            "комнату или шалаш?\n",
            "\n",
            "T = 0.9\n",
            "научим зарабатывать!\n",
            "\n",
            "T = 0.9\n",
            "в молодости битов держался агрессивно. особенно в нетрезвом состоянии. как-то раз он ударил вознесенского.\n",
            "\n",
            "T = 0.9\n",
            "какой,  спрашивает,  у тебя рост?\n",
            "\n",
            "T = 1.1\n",
            "причем тут наждак?\n",
            "\n",
            "T = 1.1\n",
            "мимисси пред высле дорговне. ойдет вотром, часоветский проздавилось раз меня.\n",
            "\n",
            "T = 1.1\n",
            "напечатали рассказ?\n",
            "на молодой и тебя ливер в ужамае себя нал это все-такниковы сфора в увеменцей. у всем была неразьюдого изговолиць и педадал тецей, занывалься иеского. евред напомой что веден и тоглатерь тутка. забравдления а сайи на золет. полежу была устануюь не пойден.\n",
            "\n",
            "T = 1.1\n",
            "все молчат.\n",
            "\n",
            "T = 1.1\n",
            "и все подтвердили, что ле сникая. я ухожу в сольнацемниюзах. ты как-то с менятерь машурки все запал. он какля пялять и вострал порес обратов.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMwBWXQ0oJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQzjoKGl8GAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}